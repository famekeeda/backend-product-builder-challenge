# ğŸ§ª Fame Keeda â€” Backend Product Builder Challenge

Build backend systems that power real-time influencer marketing, campaign orchestration, and AI-driven automation. This is your chance to show us how you think, not just how you code.

### ğŸ“ Description:
This repo contains the technical assessment for candidates applying for the **Backend/API Developer (AI Integration)** role at Fame Keeda. The challenge is designed to simulate real-world use cases we handle at scale â€” spanning campaign workflows, LLM integrations, and streaming influencer analytics.

---

## ğŸ¯ Challenge Overview

Weâ€™re scaling **Fame Dash** and **Fame Konnect**â€”AI-powered platforms connecting brands with creators through smart orchestration, predictive insights, and trend automation. This challenge is your opportunity to demonstrate how you'd contribute to building the tech behind that.

Itâ€™s not about doing everything. Itâ€™s about doing **two things really well.**

---

## ğŸ§© Choose-Your-Own-Adventure: Pick Any 2 Sections

| Track | Goal | Est. Time |
|-------|------|-----------|
| ğŸŒ€ **A. Campaign Orchestrator API** | Microservices that trigger events, fire webhooks, retry failed actions, and maintain state | 4 hrs |
| ğŸ’¡ **B. AI Brief Generator** | Use an LLM + tools/function-calling to generate a campaign brief | 3 hrs |
| ğŸ“Š **C. Streaming Metrics Pipeline** | Process influencer engagement stats in real-time; expose analytics API | 4 hrs |
| ğŸ“ˆ **D. Batch ETL + Top Performer API** | Parse 10k CSV rows, compute engagement scores, expose top-performers | 3 hrs |

---
---
## ğŸŒ€Â SectionÂ A â€“ CampaignÂ OrchestratorÂ Service
**Objective**  
Own the campaign lifecycle and deliver webhooks reliably.

| Area | Spec |
|------|------|
| **CoreÂ Endpoints** | `POST /campaigns`Â (create) â€¢ `PATCH /campaigns/:id`Â (update) |
| **EventÂ Bus** | Publish `CampaignCreated` / `CampaignUpdated` to Kafka â¬Œ RabbitMQ â¬Œ RedisÂ Streams |
| **WebhookÂ Worker** | POST each event to `https://mock.endpoint/campaign` <br>â€¢ 3â€‘try exponential backâ€‘off <br>â€¢ Deadâ€‘LetterÂ Queue after final failure |
| **AuditÂ Log** | Persist `{ id, eventType, campaignId, attempt, status, timestamp }` |
| **QueryÂ API** | `GET /logs?campaignId=` â†’ full delivery history |
| **SuccessÂ Criteria** | JWTâ€‘secured, idempotent, retries demonstrable by logs/tests, Postman docs |

---

## ğŸ’¡Â SectionÂ B â€“ AIÂ BriefÂ Generator
**Objective**  
Generate structured influencer briefs via an LLM and internal â€œtoolsâ€.

| Area | Spec |
|------|------|
| **Endpoint** | `POST /generateâ€‘brief` `{ brand, product, goal, platform }` |
| **Tools (Functions)** | `trendFetcher()` â†’ 3 hashtags â€¢ `personaClassifier()` â€¢ `creativeAngle()` |
| **LLMÂ Orchestration** | OpenAI / Ollama / HF + LangChain or functionâ€‘calling; output JSON brief (caption, hookIdeas, hashtags, CTA, tone) |
| **Caching** | Redis keyed by request hash; sensible TTL |
| **Resilience** | Retry LLM timeouts; only final failure returns 5xx |
| **SuccessÂ Criteria** | Modular prompt templates, cache <100Â ms on repeat, unit test for toolâ€‘chain |

---

## ğŸ“ŠÂ SectionÂ C â€“ StreamingÂ MetricsÂ Pipeline
**Objective**  
Ingest live engagement events and expose rolling analytics.

| Area | Spec |
|------|------|
| **Ingestion** | Consume JSON events from Kafka / RedisÂ Streams / PubSub |
| **Computation** | Maintain stats per campaign: lastÂ 1Â h â€¢ lastÂ 24Â h â€¢ cumulative |
| **Storage** | Timeâ€‘series DB (Timescale) or bucketed SQL tables |
| **QueryÂ API** | `GET /campaigns/:id/metrics` â†’ `{ window1h, window24h, total }` |
| **LatencyÂ Target** | â‰¤Â 300Â ms cold response |
| **SuccessÂ Criteria** | Consumer processes sample stream, README explains windowing, benchmark proves latency |

---

## ğŸ“ˆÂ SectionÂ D â€“ BatchÂ ETLÂ &Â Topâ€‘PerformerÂ API
**Objective**  
Crunch a 10Â kâ€‘row CSV and surface highestâ€‘engagement creators.

| Area | Spec |
|------|------|
| **ETLÂ Script** | Chunkâ€‘read `performance.csv`; compute `engRate = (likes+comments+shares)/views*100` |
| **Storage** | `campaignId, influencerId, engagementRate` |
| **API** | `GET /topâ€‘performers?campaignId=&limit=` â€¢ sorted desc |
| **RuntimeÂ Budget** | <Â 2Â min on 10Â k rows |
| **SuccessÂ Criteria** | Skips malformed rows, makeâ€‘style ETL command, unit test for rate + sorting |

---

### ğŸŒÂ Global Expectations
1. **Pick any two sections** and go deep.  
2. DockerÂ /Â `make` spinâ€‘up inÂ â‰¤Â 3 steps.  
3. No secrets in repo â€” use `.env.example`.  
4. Clear commit history + docs.  
5. Bonus extras (deployment, RAG, observability) are niceâ€‘toâ€‘haves, not required.

---

## ğŸŒŸ Bonus (Optional)

These are *not* expected â€” just fun ways to go the extra mile:

- ğŸŒ Deploy on **GCP / Cloud Run / Render** and share live endpoints  
- ğŸ§  Add **RAG/vector search** for personalized AI brief generation  
- ğŸ”” Build a **Slack/Telegram bot** for campaign status updates  
- ğŸ“ˆ Add observability with **logs, metrics, or Grafana dashboards**

---

## ğŸ›  Tech Stack Guidelines

Use what you're best at, but hereâ€™s what we love:

- **Languages:** TypeScript (Node.js), Python (FastAPI)
- **Database:** PostgreSQL, MongoDB, Redis, SQLite (for quick setup)
- **Queues/Streams:** Kafka, RabbitMQ, Redis Streams, GCP Pub/Sub
- **AI/LLMs:** OpenAI, HuggingFace, Ollama, LangChain, Function Calling APIs

---

## ğŸš€ Deliverables

- âœ… A GitHub repo (this one or forked)
- âœ… A clean and thoughtful `README.md` (thatâ€™s this file!)
- âœ… API docs â€” Swagger, Postman collection, or cURL samples
- âœ… Clear folder structure, meaningful commits
- âœ… (Optional) Loom video (3â€“5 mins) walking through your architecture and decisions

---

## ğŸ“„ README Must Include:

- Which 2 tracks you chose and why
- How to run your project locally (`docker-compose up` preferred)
- What trade-offs, assumptions, and decisions you made
- Instructions for testing or simulating API calls

---

## ğŸ§  How Youâ€™ll Be Evaluated

| Criteria                        | Weight |
|--------------------------------|--------|
| Architecture & Design Thinking | 25%    |
| Code Quality & Modularity      | 20%    |
| Correctness & Error Handling   | 20%    |
| AI/LLM Prompt + Tool Use       | 20%    |
| Documentation & DX             | 15%    |
| Bonus (If any)                 | ğŸŒŸ     |

Weâ€™re most interested in your **thought process** â€” comments, docs, even "here's what I'd do next" notes help us see how you think.

---

## ğŸ• Timeline & Submission

- **Time to complete:** 5â€“7 days from the date of receipt
- **Submit via email:** careers@famekeeda.com  
- **Subject line:** `Backend Challenge â€“ <Your Name>`  
- **Repo visibility:** Public or invite us to your private repo

We respond to every candidate within 7 days of submission. Standout entries get a deep-dive call with our tech team.

---

## âœ… Tips for Success

- Scope consciously. **Nail 2 sections > rush 4**
- Donâ€™t overengineer â€” make it clean, not complex
- Write secure, production-grade endpoints (e.g., auth, retries, caching)
- Real APIs are welcome, but good mocks are fine
- `.env.example` instead of hardcoding secrets

---

## ğŸ‘‹ Final Note

This is not a â€œtest.â€ Itâ€™s your chance to **build something real**, just like we do every week. If you love blending AI with scalable backend systems, youâ€™ll love this role.

We canâ€™t wait to see what you create.

â€” The Fame Keeda R&D Team ğŸ’«
